{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefcfdad",
   "metadata": {},
   "source": [
    "# importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a83038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import requests as req\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2907065",
   "metadata": {},
   "source": [
    "# *****************************PROBLEM 1 – Reading the data*************************\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840411f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58ea9d1c",
   "metadata": {},
   "source": [
    "# urls to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ffa2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_baits=\"https://raw.githubusercontent.com/pfrcks/clickbait-detection/master/clickbait\"\n",
    "negative_baits=\"https://raw.githubusercontent.com/pfrcks/clickbait-detection/master/not-clickbait\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c04a4",
   "metadata": {},
   "source": [
    "# A function to fetch the data from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61456203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_read_function(url,label):\n",
    "    response=req.get(url)\n",
    "    text = response.text\n",
    "    lines = text.split('\\n')\n",
    "    df=pd.DataFrame({'baits': lines})\n",
    "    df.index.name = 'Index'\n",
    "    df['Label'] = label\n",
    "    #df.to_csv('baits_data.csv', index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3846d5",
   "metadata": {},
   "source": [
    "# Read the positive and negative datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6666263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positive_dataset = my_read_function(positive_baits,'clickbait')\n",
    "negative_dataset = my_read_function(negative_baits,'not-clickbait')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f31dbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man repairs fence to contain dog, hilarity ens...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long-Term Marijuana Use Has One Crazy Side Eff...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The water from his ear trickles into the bucke...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'll Never Guess What Nick Jonas Does in the...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Cruise Liners Fill All Their Unsold Cruise...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>OITNB's Taylor Schilling and Carrie Brownstein...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Researchers have discovered the average penis ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Why it may be smart to wait to put on sunscree...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>What state has highest rate of rape in the cou...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td></td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   baits      Label\n",
       "Index                                                              \n",
       "0      Man repairs fence to contain dog, hilarity ens...  clickbait\n",
       "1      Long-Term Marijuana Use Has One Crazy Side Eff...  clickbait\n",
       "2      The water from his ear trickles into the bucke...  clickbait\n",
       "3      You'll Never Guess What Nick Jonas Does in the...  clickbait\n",
       "4      How Cruise Liners Fill All Their Unsold Cruise...  clickbait\n",
       "...                                                  ...        ...\n",
       "810    OITNB's Taylor Schilling and Carrie Brownstein...  clickbait\n",
       "811    Researchers have discovered the average penis ...  clickbait\n",
       "812    Why it may be smart to wait to put on sunscree...  clickbait\n",
       "813    What state has highest rate of rape in the cou...  clickbait\n",
       "814                                                       clickbait\n",
       "\n",
       "[815 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#reading from  the positive_dataset/click_baits_dataset\n",
    "df=pd.DataFrame(positive_dataset)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177bbd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congress Slips CISA Into a Budget Bill That's ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUI Arrest Sparks Controversy</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s unconstitutional to ban the homeless from...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Government Error Just Revealed Snowden Was t...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A toddler got meningitis. His anti-vac parents...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>Loophole means ecstasy and loads of other drug...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>Astronomers Watch a Supernova and See Reruns</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>In Indian Rapists’ Neighborhood, Smoldering An...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>Strong earthquake jolts Islamabad</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td></td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   baits          Label\n",
       "Index                                                                  \n",
       "0      Congress Slips CISA Into a Budget Bill That's ...  not-clickbait\n",
       "1                          DUI Arrest Sparks Controversy  not-clickbait\n",
       "2      It’s unconstitutional to ban the homeless from...  not-clickbait\n",
       "3      A Government Error Just Revealed Snowden Was t...  not-clickbait\n",
       "4      A toddler got meningitis. His anti-vac parents...  not-clickbait\n",
       "...                                                  ...            ...\n",
       "1570   Loophole means ecstasy and loads of other drug...  not-clickbait\n",
       "1571        Astronomers Watch a Supernova and See Reruns  not-clickbait\n",
       "1572   In Indian Rapists’ Neighborhood, Smoldering An...  not-clickbait\n",
       "1573                   Strong earthquake jolts Islamabad  not-clickbait\n",
       "1574                                                      not-clickbait\n",
       "\n",
       "[1575 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#reading from  the positive_dataset/click_baits_dataset\n",
    "df=pd.DataFrame(negative_dataset)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e353e",
   "metadata": {},
   "source": [
    "# Combining  the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce915c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_dataset = pd.concat([positive_dataset, negative_dataset], ignore_index=True)\n",
    "df=pd.DataFrame(combined_dataset)\n",
    "\n",
    "df.to_csv(\"combined.csv\",index=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71fa7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man repairs fence to contain dog, hilarity ens...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long-Term Marijuana Use Has One Crazy Side Eff...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The water from his ear trickles into the bucke...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'll Never Guess What Nick Jonas Does in the...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Cruise Liners Fill All Their Unsold Cruise...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Could Queen Elizabeth Veto Brexit?</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This Is the Worst Color to Paint Your Kitchen</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Shocking Truth About Sugar</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               baits      Label\n",
       "0  Man repairs fence to contain dog, hilarity ens...  clickbait\n",
       "1  Long-Term Marijuana Use Has One Crazy Side Eff...  clickbait\n",
       "2  The water from his ear trickles into the bucke...  clickbait\n",
       "3  You'll Never Guess What Nick Jonas Does in the...  clickbait\n",
       "4  How Cruise Liners Fill All Their Unsold Cruise...  clickbait\n",
       "5                 Could Queen Elizabeth Veto Brexit?  clickbait\n",
       "6      This Is the Worst Color to Paint Your Kitchen  clickbait\n",
       "7                     The Shocking Truth About Sugar  clickbait"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#reading the first 8 rows of the combined dataset\n",
    "df.head(8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a895972",
   "metadata": {},
   "source": [
    "# Shuffling  the combined dataset using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2755f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create an array of indices from 0 to the length of the combined dataset\n",
    "shuffled_indices = np.arange(len(combined_dataset))\n",
    "# Shuffle the array of indices randomly using numpy's random.shuffle function\n",
    "np.random.shuffle(shuffled_indices)\n",
    "# Use the shuffled indices to rearrange the rows of the combined dataset, creating the shuffled dataset\n",
    "shuffled_dataset = combined_dataset.iloc[shuffled_indices]\n",
    "df2=pd.DataFrame(shuffled_dataset)\n",
    "df2.to_csv(\"shuffled.csv\",index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af547d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>And the winning #Powerball numbers are...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Chuck Blazer: Fifa imposes life ban from footb...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>What if Apple Made iPhones in the US? Here’s H...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>North Korea announces it conducted nuclear test</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Boaty McBoatface wins poll to name polar resea...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>One Day Later, Anonymous Already Takes Down 3,...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>Teen Who Worked In Corner Shop For 10 Weeks To...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>It is rare for a new animal species to emerge ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>You Won’t Believe What 11-Time Olympic Medalis...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>Turkmenistan president outlaws all sale of tob...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "769           And the winning #Powerball numbers are...      clickbait\n",
       "2114  Chuck Blazer: Fifa imposes life ban from footb...  not-clickbait\n",
       "572   What if Apple Made iPhones in the US? Here’s H...      clickbait\n",
       "2003    North Korea announces it conducted nuclear test  not-clickbait\n",
       "1000  Boaty McBoatface wins poll to name polar resea...  not-clickbait\n",
       "955   One Day Later, Anonymous Already Takes Down 3,...  not-clickbait\n",
       "1257  Teen Who Worked In Corner Shop For 10 Weeks To...  not-clickbait\n",
       "1187  It is rare for a new animal species to emerge ...  not-clickbait\n",
       "412   You Won’t Believe What 11-Time Olympic Medalis...      clickbait\n",
       "2088  Turkmenistan president outlaws all sale of tob...  not-clickbait"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading the first ten rows of the shuffled_dataset\n",
    "df=pd.DataFrame(shuffled_dataset)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06571b4f",
   "metadata": {},
   "source": [
    "# Split the shuffled dataset into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3cd3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_percentage = 0.72  # 72% for training\n",
    "validation_data_percentage = 0.08  # 8% for validation\n",
    "test_data_percentage = 0.20  # 20% for testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15e1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "total_samples = len(shuffled_dataset) #number of rows in the combined dataset\n",
    "train_data_samples = int(train_data_percentage * total_samples) #number of rows in the training dataset \n",
    "validation_data_samples = int(validation_data_percentage * total_samples) #number of rows in the validation dataset\n",
    "test_data_samples = total_samples - train_data_samples - validation_data_samples #number of rows in the testing dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f20314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "total sample or the number of rows =2390 samples/rows\n",
      "validation samples or the number of rows =191 samples/rows\n",
      "Training samples or the number of rows =1720 samples/rows\n",
      "test samples or the number of rows =479 samples/rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#printing the number of rows/ samples in each dataset\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"total sample or the number of rows ={total_samples} samples/rows\")\n",
    "print(f\"validation samples or the number of rows ={validation_data_samples} samples/rows\")\n",
    "print(f\"Training samples or the number of rows ={train_data_samples} samples/rows\")\n",
    "print(f\"test samples or the number of rows ={test_data_samples} samples/rows\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87b3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spliting the dataset into training and the remaining data (remaining_data)\n",
    "training_data, remaining_data = train_test_split(shuffled_dataset, test_size=(1 - train_data_percentage))\n",
    "\n",
    "# Split the remaining data into validation and test sets\n",
    "validation_data, test_data = train_test_split(remaining_data, test_size=test_data_percentage / (test_data_percentage + validation_data_percentage))\n",
    "#saving the datasets \n",
    "train_dataset=pd.DataFrame(training_data) #training dataset\n",
    "train_dataset.to_csv(\"traning_data.csv\",index=False)\n",
    "\n",
    "validating_dataset=pd.DataFrame(validation_data) #validating  set\n",
    "validating_dataset.to_csv(\"validating_data.csv\",index=False)\n",
    "\n",
    "testing_dataset=pd.DataFrame(test_data) #testing set \n",
    "testing_dataset.to_csv('testing_dataset.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44273b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Oscars 2016: And the winners are...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>You’ll Be Shocked at How Little An Oscar Statu...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>Brussels attacks: Zaventem and Maelbeek bombs ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Saudi court sentences poet to death for renoun...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Mayor of Santa Ana Named in Pot Shop Raid Lawsuit</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>Greeks defy Europe with overwhelming referendu...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>‘Game Of Thrones’: How Will Brexit Impact Fund...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Enormous \"Frog Penis\" That Went Viral Isn't A ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Man swallowed a microSD card and you won't bel...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>\"Shoot him and I'll give you a medal\" - Philip...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "746                 Oscars 2016: And the winners are...      clickbait\n",
       "474   You’ll Be Shocked at How Little An Oscar Statu...      clickbait\n",
       "1114  Brussels attacks: Zaventem and Maelbeek bombs ...  not-clickbait\n",
       "1634  Saudi court sentences poet to death for renoun...  not-clickbait\n",
       "1059  Mayor of Santa Ana Named in Pot Shop Raid Lawsuit  not-clickbait\n",
       "...                                                 ...            ...\n",
       "2021  Greeks defy Europe with overwhelming referendu...  not-clickbait\n",
       "283   ‘Game Of Thrones’: How Will Brexit Impact Fund...      clickbait\n",
       "149   Enormous \"Frog Penis\" That Went Viral Isn't A ...      clickbait\n",
       "32    Man swallowed a microSD card and you won't bel...      clickbait\n",
       "1870  \"Shoot him and I'll give you a medal\" - Philip...  not-clickbait\n",
       "\n",
       "[1720 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading from each and every dataset after split\n",
    "train_dataset #reading from the training dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc9a59a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Crowdfunding for Kanye’s debt raises a meager...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>New York City sets new record: no murders for ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>Lab tech allegedly faked result in drug case; ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Oil price falls below $35 a barrel to fresh 11...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Chicago police unions fight to destroy decades...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Why Do Cats Come To The Bathroom With You?</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>Japan furious at UNESCO listing Nanjing Massac...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Why obsessed hockey fans are updating ‘NHL 200...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>Officers in Vineland fatal arrest named by 'An...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Stephen Hawking announces $100 million hunt fo...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "248    Crowdfunding for Kanye’s debt raises a meager...      clickbait\n",
       "977   New York City sets new record: no murders for ...  not-clickbait\n",
       "925   Lab tech allegedly faked result in drug case; ...  not-clickbait\n",
       "2097  Oil price falls below $35 a barrel to fresh 11...  not-clickbait\n",
       "1028  Chicago police unions fight to destroy decades...  not-clickbait\n",
       "...                                                 ...            ...\n",
       "316          Why Do Cats Come To The Bathroom With You?      clickbait\n",
       "2159  Japan furious at UNESCO listing Nanjing Massac...  not-clickbait\n",
       "213   Why obsessed hockey fans are updating ‘NHL 200...      clickbait\n",
       "1222  Officers in Vineland fatal arrest named by 'An...  not-clickbait\n",
       "1807  Stephen Hawking announces $100 million hunt fo...  not-clickbait\n",
       "\n",
       "[479 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading from the testing dataset\n",
    "testing_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4724c679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>Anthony Bourdain Reveals His Favorite City for...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>Student suspended after carrying classmate hav...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>China bans depictions of gay people on television</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>What if Apple Made iPhones in the US? Here’s H...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>You'll Never Believe How Queen Elizabeth's Cor...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Jennifer Garner Dating Her Accountant?</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Details about   1960 Volkswagen Beetle - Classic</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>Planned Parenthood sues anti-abortion group be...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>Apple says the FBI is making access demands ev...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>U.S. Kills Leader of ISIS in Libya</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "580   Anthony Bourdain Reveals His Favorite City for...      clickbait\n",
       "933   Student suspended after carrying classmate hav...  not-clickbait\n",
       "1692  China bans depictions of gay people on television  not-clickbait\n",
       "572   What if Apple Made iPhones in the US? Here’s H...      clickbait\n",
       "517   You'll Never Believe How Queen Elizabeth's Cor...      clickbait\n",
       "...                                                 ...            ...\n",
       "25               Jennifer Garner Dating Her Accountant?      clickbait\n",
       "286    Details about   1960 Volkswagen Beetle - Classic      clickbait\n",
       "1422  Planned Parenthood sues anti-abortion group be...  not-clickbait\n",
       "1505  Apple says the FBI is making access demands ev...  not-clickbait\n",
       "2061                 U.S. Kills Leader of ISIS in Libya  not-clickbait\n",
       "\n",
       "[191 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading from the validation  dataset\n",
    "validating_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc31e1",
   "metadata": {},
   "source": [
    "# Calculating the \"target rate\" for each dataset (training,validation and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "014e9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_target_rate = (train_dataset['Label'] == 'clickbait').mean()\n",
    "validation_data_target_rate = (validating_dataset['Label'] == 'clickbait').mean()\n",
    "test_data_target_rate = (testing_dataset['Label'] == 'clickbait').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67be6a",
   "metadata": {},
   "source": [
    "# what % of the three datasets is t is labeled as clickbait?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8695054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "33.26% of the training data is labeled as clickbait\n",
      "36.65% of the validating data is labeled as clickbait\n",
      "36.120000000000005% of the testing data is labeled as clickbait\n"
     ]
    }
   ],
   "source": [
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"{train_data_target_rate.round(4)*100}% of the training data is labeled as clickbait\")\n",
    "print(f\"{validation_data_target_rate.round(4)*100}% of the validating data is labeled as clickbait\")\n",
    "print(f\"{test_data_target_rate.round(4)*100}% of the testing data is labeled as clickbait\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7013a",
   "metadata": {},
   "source": [
    "# **********************  PROBLEM 3 – Training a single Bag-of-Words (BOW) Text Classifier ***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df9cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Loading the training and validation datasets\n",
    "validating_dataset  #the dataset containing the validating data\n",
    "train_dataset #the dataset containing the traingin data\n",
    "\n",
    "\n",
    "# Map labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "train_dataset['Label'] = (train_dataset['Label'] == 'clickbait').astype(int)\n",
    "validating_dataset['Label'] = (validating_dataset['Label'] == 'clickbait').astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Creating  a Pipeline with CountVectorizer and MultinomialNB\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "# Fiting  the classifier on the training dataset\n",
    "pipeline.fit(train_dataset['baits'], train_dataset['Label'])\n",
    "\n",
    "\n",
    "# Predict on the training and validation datasets\n",
    "train_predictions = pipeline.predict(train_dataset['baits'])\n",
    "validation_predictions = pipeline.predict(validating_dataset['baits'])\n",
    "\n",
    "\n",
    "\n",
    "# Computing  precision, recall, and F1-score for training and validation datasets with zero_division='warn'\n",
    "train_precision = precision_score(train_dataset['Label'], train_predictions, pos_label=1, zero_division='warn')\n",
    "train_recall = recall_score(train_dataset['Label'], train_predictions, pos_label=1, zero_division='warn')\n",
    "train_f1 = f1_score(train_dataset['Label'], train_predictions, pos_label=1, zero_division='warn')\n",
    "\n",
    "validation_precision = precision_score(validating_dataset['Label'], validation_predictions, pos_label=1, zero_division='warn')\n",
    "validation_recall = recall_score(validating_dataset['Label'], validation_predictions, pos_label=1, zero_division='warn')\n",
    "validation_f1 = f1_score(validating_dataset['Label'], validation_predictions, pos_label=1, zero_division='warn')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dabbaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Training Precision is  0.9930434782608696  or  99.3%\n",
      "Training Recall is 0.9982517482517482  or 99.83%\n",
      "Training F1-score is  0.995640802092415 or 99.83%\n",
      "\n",
      "\n",
      "Validation Precision is 0.9264705882352942 or 92.65% \n",
      "Validation Recall is  0.9 or 92.65%\n",
      "Validation F1-score is 0.9130434782608695 or 91.3%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"Training Precision is  {train_precision}  or  {train_precision.round(4)*100}%\")\n",
    "print(f\"Training Recall is {train_recall}  or {train_recall.round(4)*100}%\")\n",
    "print(f\"Training F1-score is  {train_f1} or {train_recall.round(4)*100}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Validation Precision is {validation_precision} or {validation_precision.round(4)*100}% \")\n",
    "print(f\"Validation Recall is  {validation_recall} or {validation_precision.round(4)*100}%\")\n",
    "print(f\"Validation F1-score is { validation_f1} or {validation_f1.round(4)*100}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11002a17",
   "metadata": {},
   "source": [
    "# ********************** PROBLEM 4 – Hyperparameter Tuning**********************\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fed41b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Top Results\n",
      "                                               params  validation_precision  \\\n",
      "0   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "1   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "16  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "15  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "14  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "\n",
      "    validation_recall  validation_f1  \n",
      "0                 1.0            1.0  \n",
      "1                 1.0            1.0  \n",
      "16                1.0            1.0  \n",
      "15                1.0            1.0  \n",
      "14                1.0            1.0  \n",
      "Bottom Results\n",
      "                                               params  validation_precision  \\\n",
      "5   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "4   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "3   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "2   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "17  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "\n",
      "    validation_recall  validation_f1  \n",
      "5                 1.0            1.0  \n",
      "4                 1.0            1.0  \n",
      "3                 1.0            1.0  \n",
      "2                 1.0            1.0  \n",
      "17                1.0            1.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mapping  labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "train_dataset['Label'] = (train_dataset['Label'] == 'clickbait').astype(int)\n",
    "validating_dataset['Label'] = (validating_dataset['Label'] == 'clickbait').astype(int)\n",
    "\n",
    "\n",
    "# Defining a grid of hyperparameters to search\n",
    "parameter_grid = {\n",
    "    'vectorizer__max_df': [0.5, 0.75, 1.0],  # Vary max_df for CountVectorizer\n",
    "    'classifier__alpha': [1.0, 0.5, 0.1],     # Vary smoothing for MultinomialNB\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)]  # Include or exclude bigrams in CountVectorizer\n",
    "}\n",
    "\n",
    "\n",
    "# Initializing  an empty  list to store the results\n",
    "results = []\n",
    "\n",
    "\n",
    "# Iterating  over the parameter grid\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    # Creating  a Pipeline with CountVectorizer and MultinomialNB with the current parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(max_df=params['vectorizer__max_df'], ngram_range=params['vectorizer__ngram_range'])),\n",
    "        ('classifier', MultinomialNB(alpha=params['classifier__alpha']))\n",
    "    ])\n",
    "    \n",
    "\n",
    "    # Fiting  the classifier on the training dataset\n",
    "    pipeline.fit(train_dataset['baits'], train_dataset['Label'])\n",
    "\n",
    "    \n",
    "    # Predicting  on the validation dataset\n",
    "    validation_predictions = pipeline.predict(validating_dataset['baits'])\n",
    "\n",
    "    \n",
    "    # Computing  precision, recall, and F1-score for validation dataset\n",
    "    validation_precision = precision_score(validating_dataset['Label'], validation_predictions,zero_division=1)\n",
    "    validation_recall = recall_score(validating_dataset['Label'], validation_predictions,zero_division=1)\n",
    "    validation_f1 = f1_score(validating_dataset['Label'], validation_predictions,zero_division=1)\n",
    "\n",
    "    \n",
    "    # Storing  the results\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'validation_precision': validation_precision,\n",
    "        'validation_recall': validation_recall,\n",
    "        'validation_f1': validation_f1\n",
    "    })\n",
    "\n",
    "# Converting  results to a DataFrame for analysis\n",
    "results_dataframe = pd.DataFrame(results)\n",
    "\n",
    "# Sorting  the results by F1-score in descending order\n",
    "results_dataframe = results_dataframe.sort_values(by='validation_f1', ascending=False)\n",
    "\n",
    "# Displaying  the top and bottom results \n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(\"Top Results\")\n",
    "print(results_dataframe.head())\n",
    "print(\"Bottom Results\")\n",
    "print(results_dataframe.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e1519",
   "metadata": {},
   "source": [
    "# *********************************PROBLEM 5 – Model selection ************************\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "251f7a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Best Model - Parameters \n",
      "{'classifier__alpha': 1.0, 'vectorizer__max_df': 0.5, 'vectorizer__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      " Validation F1-Score value  of  the Best Model is  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#To select the best model from the results of the hyperparameter tuning,\n",
    "#i choose the one that achieved the highest F1-score on the validation set. how do choose.\n",
    "\n",
    "\n",
    "# Finding  the best model based on validation F1-score values\n",
    "best_model = max(results, key=lambda x: x['validation_f1'])\n",
    "\n",
    "# Displaying  the best model's parameters and validation F1-score  value\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(\"Best Model - Parameters \")\n",
    "print(best_model['params'])\n",
    "print(\"\\n\")\n",
    "print(\" Validation F1-Score value  of  the Best Model is \", best_model['validation_f1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e2061a0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "#applying the  model to my  test set and computing the  precision, recall, and F1-score values\n",
    "    \n",
    "   # Creating  a pipeline with the best model's parameters\n",
    "best_model_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_df=best_model['params']['vectorizer__max_df'], ngram_range=best_model['params']['vectorizer__ngram_range'])),\n",
    "    ('classifier', MultinomialNB(alpha=best_model['params']['classifier__alpha']))\n",
    "])\n",
    "\n",
    "# Fiting my  best model on the training dataset\n",
    "best_model_pipeline.fit(train_dataset['baits'], train_dataset['Label'])\n",
    "\n",
    "# Predicting  on the test dataset\n",
    "test_predictions = best_model_pipeline.predict(testing_dataset['baits'])\n",
    "\n",
    "#removing posible NAN values\n",
    "clean_testing_data = testing_dataset.dropna()\n",
    "\n",
    "# Convert true labels to numeric format\n",
    "clean_testing_data['Label'] = clean_testing_data['Label'].map({'clickbait': 1, 'not-clickbait': 0})\n",
    "\n",
    "# Computing the  precision, recall, and F1-score values  for the test dataset\n",
    "test_precision = precision_score(clean_testing_data['Label'], test_predictions,zero_division=1)\n",
    "test_recall = recall_score(clean_testing_data['Label'], test_predictions)\n",
    "test_f1 = f1_score(clean_testing_data['Label'], test_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cde08ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "These are Test Set Metrics for Best Model \n",
      "Precision  1.0\n",
      "Recall  0.0\n",
      "F1-Score  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "# Display the test set results\n",
    "print(\"These are Test Set Metrics for Best Model \")\n",
    "print(\"Precision \", test_precision)\n",
    "print(\"Recall \", test_recall)\n",
    "print(\"F1-Score \" , test_f1)\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b84f8f9",
   "metadata": {},
   "source": [
    "# ************************PROBLEM 6 – Key Indicators*********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0986df59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Initializing  and training  a Multinomial Naive Bayes classifier\u001b[39;00m\n\u001b[0;32m     25\u001b[0m clf \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Geting  the feature log probabilities for the \"clickbait\" class\u001b[39;00m\n\u001b[0;32m     30\u001b[0m clickbait_log_probs \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mfeature_log_prob_[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    748\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:578\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    577\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1162\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1184\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1183\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_numeric \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "\n",
    "#Convert the text to lowercase to ensure consistency.\n",
    "train_dataset['baits'] = train_dataset['baits'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Defining  a dictionary to map labels to binary values\n",
    "label_mapping = {'clickbait': 1, 'not-clickbait': 0} # Mapping  labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "\n",
    "\n",
    "\n",
    "# Using  the map method to update my  'Label' column\n",
    "train_dataset['Label'] = train_dataset['Label'].map(label_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# Creating  a CountVectorizer to extract key words\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2)) \n",
    "\n",
    "\n",
    "# Transforming  the training data into a feature matrix\n",
    "X_train = vectorizer.fit_transform(train_dataset['baits'])\n",
    "\n",
    "\n",
    "# Initializing  and training  a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, train_dataset['Label'])\n",
    "\n",
    "\n",
    "# Geting  the feature log probabilities for the \"clickbait\" class\n",
    "clickbait_log_probs = clf.feature_log_prob_[1]\n",
    "\n",
    "\n",
    "# Geting the corresponding vocabulary words\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "# Creating  a DataFrame to analyze the results\n",
    "clickbait_dataframe = pd.DataFrame({'Word': feature_names, 'Log Probability': clickbait_log_probs})\n",
    "\n",
    "\n",
    "# Sorting  the DataFrame by log probability in descending order\n",
    "clickbait_dataframe = clickbait_dataframe.sort_values(by='Log Probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c89ab08b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clickbait_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Display the top 5 words with the highest log probability\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m top_clickbait_words \u001b[38;5;241m=\u001b[39m \u001b[43mclickbait_dataframe\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m********************* OUTPUT ********************\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 5 Clickbait Indicator Words\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clickbait_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the top 5 words with the highest log probability\n",
    "top_clickbait_words = clickbait_dataframe.head(6)\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(\"Top 5 Clickbait Indicator Words\")\n",
    "print(top_clickbait_words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c477e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d48c8",
   "metadata": {},
   "source": [
    "# ************** PROBLEM 7 – Regular expression *************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d51a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeae447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d31aa9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_clickbait_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# A list of words that are recognized as clickbaits in the previous Question\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m top_keywords \u001b[38;5;241m=\u001b[39m \u001b[43mtop_clickbait_words\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWord\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Constructing  a regular expression pattern to match any of the top keywords with word boundaries\u001b[39;00m\n\u001b[0;32m      5\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(?:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(re\u001b[38;5;241m.\u001b[39mescape(keyword) \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m top_keywords) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_clickbait_words' is not defined"
     ]
    }
   ],
   "source": [
    "# A list of words that are recognized as clickbaits in the previous Question\n",
    "top_keywords = top_clickbait_words['Word'].unique()\n",
    "\n",
    "# Constructing  a regular expression pattern to match any of the top keywords with word boundaries\n",
    "pattern = r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in top_keywords) + r')\\b'\n",
    "\n",
    "#A testing message\n",
    "text = \"you will be a billionaire within two days if you do the following. Follow this steps .\"\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "# Using  re.search function to find matches in the text\n",
    "if re.search(pattern, text):\n",
    "    print(\"Keyword found in the text.\")\n",
    "else:\n",
    "    print(\"Keyword not found in the text.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8689fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f25851e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_keywords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 26\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(re\u001b[38;5;241m.\u001b[39msearch(pattern, text))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Applying  the function to  test_dataset \u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m testing_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtesting_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbaits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyword_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Calculating the  precision and recall values \u001b[39;00m\n\u001b[0;32m     32\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(testing_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m], testing_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m], zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[29], line 18\u001b[0m, in \u001b[0;36mkeyword_classifier\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkeyword_classifier\u001b[39m(text):\n\u001b[1;32m---> 18\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(?:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(re\u001b[38;5;241m.\u001b[39mescape(keyword) \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtop_keywords\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(re\u001b[38;5;241m.\u001b[39msearch(pattern, text))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_keywords' is not defined"
     ]
    }
   ],
   "source": [
    "#removing any nans\n",
    "\n",
    "testing_dataset=testing_dataset.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# Defining  a dictionary to map labels to binary values\n",
    "label_mapping = {'clickbait': 1, 'not-clickbait': 0} # Mapping  labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "\n",
    "\n",
    "# Using  the map method to update my  'Label' column\n",
    "testing_dataset['Label'] = testing_dataset['Label'].map(label_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# Creating a function  to check if any top keywords are present in the text from the test data_set\n",
    "def keyword_classifier(text):\n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in top_keywords) + r')\\b'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Applying  the function to  test_dataset \n",
    "\n",
    "testing_dataset['Predicted'] = testing_dataset['baits'].apply(keyword_classifier)\n",
    "\n",
    "\n",
    "\n",
    "# Calculating the  precision and recall values \n",
    "\n",
    "precision = precision_score(testing_dataset['Label'], testing_dataset['Predicted'], zero_division='warn')\n",
    "\n",
    "recall = recall_score(testing_dataset['Label'], testing_dataset['Predicted'], zero_division='warn')\n",
    "\n",
    "f1=f1_score(testing_dataset['Label'], testing_dataset['Predicted'], zero_division='warn')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7095d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e0d0441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "The Precision of this classifier is 0.32589285714285715 or  32.59%\n",
      "The Recall of this classifier is  0.46496815286624205 or  46.5%\n",
      "The Recall of this classifier is  0.3832020997375329 or  38.32%\n"
     ]
    }
   ],
   "source": [
    "#printing the results \n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"The Precision of this classifier is {precision} or  {precision.round(4)*100}%\")\n",
    "print(f\"The Recall of this classifier is  {recall} or  {recall.round(4)*100}%\")\n",
    "print(f\"The Recall of this classifier is  {f1} or  {f1.round(4)*100}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
